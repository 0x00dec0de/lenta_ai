{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Генерация заголовков новостей с использованием Word Embeddings\n",
    "За основу взята реализация одного из заданий на курсе [Udacity Deep Learning Foundation](https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import helper # Вспомогательные функции для сохранения и загрузки модели и параметров\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Здесь задаем, на каких данных будем обучать сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Все статьи\n",
    "mode = \"full\"       \n",
    "\n",
    "# Выборка (~800 статей)\n",
    "# mode = \"sample\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Откроем файл с предварительно обработанным текстом (см. ноутбук preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/headers_' + mode + '.txt'\n",
    "text = helper.load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Данные\n",
    "Посмотрим, что внутри текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Немного статистики\n",
      "Уникальных слов: 80342\n",
      "Количество заголовков: 58604\n",
      "Среднее количество слов в заголовке: 7.871851750733739\n",
      "\n",
      "Заголовки с 0 по 10:\n",
      "рпцз призвала вынести ленина из мавзолея и начать декоммунизацию\n",
      "найдены тела пропавших моряков с американского эсминца\n",
      "полиция мэриленда арестовала подозреваемых в убийстве россиянина зиберова\n",
      "концерт рэпера басты в одессе отменили после угроз украинских националистов\n",
      "более 200 тысяч человек выступили против презумпции доверия к полицейским\n",
      "мутко раскритиковал газзаева за ответ путину во время прямой линии\n",
      "у меня не железные яйца\n",
      "ковалев прокомментировал второе подряд поражение от уорда\n",
      "в фсвтс прокомментировали поставки корабельных вертолетов ка-52к в египет\n",
      "украинские националисты отобрали флаг лгбт у участников гей-парада в киеве\n"
     ]
    }
   ],
   "source": [
    "# Диапазон номеров выводимых заголовков\n",
    "view_sentence_range = (0, 10)\n",
    "\n",
    "print('Немного статистики')\n",
    "print('Уникальных слов: {}'.format(len({word: None for word in text.split(\" \")})))\n",
    "sentences = [sentence for sentence in text.split('. ')]\n",
    "print('Количество заголовков: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Среднее количество слов в заголовке: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('Заголовки с {} по {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('. ')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Предварительная обработка\n",
    "\n",
    "### Создание словарей\n",
    "Чтобы создать word embedding, нужно преобразовать слова в числовые айдишники. Функция ниже создает и возвращает два словаря:\n",
    "- `vocab_to_int`: Слово -> ID \n",
    "- `int_to_vocab`: ID -> Слово\n",
    "\n",
    "`text` - Текст со всеми заголовками, разделенный на слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_tables(text):\n",
    "\n",
    "    counter = Counter(text)\n",
    "    vocab = sorted(counter, key=counter.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Токенизация знаков препинания\n",
    "Мы будем разделять текст на массив слов, используя пробел в качестве разделителя. При этом в исходном тексте знаки пунктуации в общем случае \"приклеены\" к слову (не отделены пробелами), поэтому нейронной сети будет сложно отличить слово \"привет\" от \"привет!\". \n",
    "\n",
    "Чтобы предотвратить такие случаи, заменим имеющиеся в тексте знаки пунктуации на отдельные токены. \n",
    "\n",
    "_(Большая часть знаков уже была удалена в ходе препроцессинга, но я решил не менять этот код, оставив его таким, какой он был в изначальном варианте.)_\n",
    "\n",
    "Этот словарь будет использоваться для преобразования знаков препинания в токены, добавляя пробел перед ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def token_lookup():\n",
    "    tokens = {\n",
    "        \".\": \"||PERIOD||\",\n",
    "        \",\": \"||COMMA||\",\n",
    "        '\"': \"||QUOT_MARK||\",\n",
    "        \";\": \"||SEMICOL||\",\n",
    "        \"!\": \"||EXCL_MARK||\",\n",
    "        \"?\": \"||QUEST_MARK||\",\n",
    "        \"(\": \"||L_PARENTH||\",\n",
    "        \")\": \"||R_PARENTH||\",\n",
    "        \"--\": \"||DASH||\",\n",
    "        \"\\n\": \"||RETURN||\"\n",
    "    }\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Обработаем текст и сохраняем его, как контрольную точку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загружаем текст и словари"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ради любопытства взглянем на какой-нибудь из словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '||period||',\n",
       " 1: 'в',\n",
       " 2: 'на',\n",
       " 3: 'с',\n",
       " 4: 'о',\n",
       " 5: 'и',\n",
       " 6: 'за',\n",
       " 7: 'по',\n",
       " 8: 'россии',\n",
       " 9: 'из',\n",
       " 10: 'сша',\n",
       " 11: 'для',\n",
       " 12: 'от',\n",
       " 13: 'из-за',\n",
       " 14: 'к',\n",
       " 15: 'об',\n",
       " 16: '||comma||',\n",
       " 17: 'у',\n",
       " 18: 'после',\n",
       " 19: 'рассказал',\n",
       " 20: 'назвал',\n",
       " 21: 'сми',\n",
       " 22: 'трампа',\n",
       " 23: 'во',\n",
       " 24: 'москве',\n",
       " 25: 'под',\n",
       " 26: 'путин',\n",
       " 27: 'видео',\n",
       " 28: 'рублей',\n",
       " 29: 'при',\n",
       " 30: 'против',\n",
       " 31: 'не',\n",
       " 32: 'до',\n",
       " 33: 'долларов',\n",
       " 34: 'украины',\n",
       " 35: 'сети',\n",
       " 36: 'россиян',\n",
       " 37: 'суд',\n",
       " 38: 'сирии',\n",
       " 39: 'российских',\n",
       " 40: 'предложили',\n",
       " 41: 'тысяч',\n",
       " 42: 'человек',\n",
       " 43: 'глава',\n",
       " 44: 'назвали',\n",
       " 45: 'трамп',\n",
       " 46: 'года',\n",
       " 47: 'порошенко',\n",
       " 48: 'предложил',\n",
       " 49: 'рассказали',\n",
       " 50: 'время',\n",
       " 51: 'умер',\n",
       " 52: 'нашли',\n",
       " 53: 'сообщили',\n",
       " 54: 'россию',\n",
       " 55: 'области',\n",
       " 56: 'со',\n",
       " 57: 'россия',\n",
       " 58: 'путина',\n",
       " 59: 'заявил',\n",
       " 60: 'его',\n",
       " 61: 'без',\n",
       " 62: 'миллионов',\n",
       " 63: 'лет',\n",
       " 64: 'украине',\n",
       " 65: 'власти',\n",
       " 66: 'мира',\n",
       " 67: 'задержали',\n",
       " 68: 'иг',\n",
       " 69: 'два',\n",
       " 70: 'российский',\n",
       " 71: 'подмосковье',\n",
       " 72: 'отказался',\n",
       " 73: 'над',\n",
       " 74: 'пообещал',\n",
       " 75: 'призвал',\n",
       " 76: 'узнали',\n",
       " 77: 'российские',\n",
       " 78: 'погибли',\n",
       " 79: 'мид',\n",
       " 80: 'стал',\n",
       " 81: 'новый',\n",
       " 82: 'три',\n",
       " 83: 'дело',\n",
       " 84: 'названы',\n",
       " 85: 'полиция',\n",
       " 86: 'киеве',\n",
       " 87: 'перед',\n",
       " 88: 'кндр',\n",
       " 89: 'бывший',\n",
       " 90: 'россией',\n",
       " 91: 'москвы',\n",
       " 92: 'число',\n",
       " 93: 'российского',\n",
       " 94: 'более',\n",
       " 95: 'госдуме',\n",
       " 96: '-',\n",
       " 97: 'двух',\n",
       " 98: 'детей',\n",
       " 99: 'году',\n",
       " 100: 'обвинили',\n",
       " 101: 'впервые',\n",
       " 102: 'получил',\n",
       " 103: 'прокомментировал',\n",
       " 104: 'делу',\n",
       " 105: 'сборной',\n",
       " 106: 'крыма',\n",
       " 107: 'дтп',\n",
       " 108: 'турции',\n",
       " 109: 'оон',\n",
       " 110: 'президент',\n",
       " 111: 'песков',\n",
       " 112: 'ради',\n",
       " 113: 'смерти',\n",
       " 114: 'показали',\n",
       " 115: 'туристов',\n",
       " 116: 'крыму',\n",
       " 117: 'первый',\n",
       " 118: 'мире',\n",
       " 119: 'президента',\n",
       " 120: 'про',\n",
       " 121: 'заподозрили',\n",
       " 122: 'нового',\n",
       " 123: 'рассказала',\n",
       " 124: 'евро',\n",
       " 125: 'бывшего',\n",
       " 126: 'обвинил',\n",
       " 127: 'сообщил',\n",
       " 128: 'минобороны',\n",
       " 129: 'человека',\n",
       " 130: 'день',\n",
       " 131: 'ес',\n",
       " 132: 'пять',\n",
       " 133: 'донбассе',\n",
       " 134: 'цб',\n",
       " 135: 'заявили',\n",
       " 136: 'днр',\n",
       " 137: 'процентов',\n",
       " 138: 'появилось',\n",
       " 139: 'вышел',\n",
       " 140: 'миллиардов',\n",
       " 141: 'дома',\n",
       " 142: 'названа',\n",
       " 143: 'все',\n",
       " 144: 'объяснил',\n",
       " 145: 'петербурге',\n",
       " 146: 'кремле',\n",
       " 147: '10',\n",
       " 148: 'оценили',\n",
       " 149: 'нато',\n",
       " 150: 'матче',\n",
       " 151: 'новые',\n",
       " 152: 'миллиона',\n",
       " 153: 'германии',\n",
       " 154: 'подмосковья',\n",
       " 155: 'себя',\n",
       " 156: 'отказались',\n",
       " 157: 'россияне',\n",
       " 158: 'метро',\n",
       " 159: 'убийстве',\n",
       " 160: 'санкций',\n",
       " 161: '||excl_mark||',\n",
       " 162: 'футболист',\n",
       " 163: 'новой',\n",
       " 164: 'украину',\n",
       " 165: 'способ',\n",
       " 166: 'франции',\n",
       " 167: 'кремль',\n",
       " 168: 'депутат',\n",
       " 169: 'через',\n",
       " 170: 'стали',\n",
       " 171: 'сняли',\n",
       " 172: '2017',\n",
       " 173: 'оценил',\n",
       " 174: 'работу',\n",
       " 175: 'главы',\n",
       " 176: 'американский',\n",
       " 177: 'жизни',\n",
       " 178: 'киев',\n",
       " 179: 'санкции',\n",
       " 180: 'российской',\n",
       " 181: 'подробности',\n",
       " 182: 'мужчина',\n",
       " 183: 'погиб',\n",
       " 184: 'самолет',\n",
       " 185: '20',\n",
       " 186: 'еще',\n",
       " 187: 'начала',\n",
       " 188: 'новых',\n",
       " 189: 'европы',\n",
       " 190: 'дела',\n",
       " 191: 'планах',\n",
       " 192: 'медведев',\n",
       " 193: 'между',\n",
       " 194: 'часы',\n",
       " 195: 'донбасса',\n",
       " 196: 'сроки',\n",
       " 197: 'военные',\n",
       " 198: 'мвд',\n",
       " 199: 'теракта',\n",
       " 200: 'самолета',\n",
       " 201: 'начали',\n",
       " 202: 'попал',\n",
       " 203: 'показал',\n",
       " 204: 'выборах',\n",
       " 205: 'готовности',\n",
       " 206: 'назвала',\n",
       " 207: 'год',\n",
       " 208: 'обнаружили',\n",
       " 209: 'ребенка',\n",
       " 210: 'рады',\n",
       " 211: 'ее',\n",
       " 212: 'стала',\n",
       " 213: 'людей',\n",
       " 214: 'всех',\n",
       " 215: 'дом',\n",
       " 216: 'жителей',\n",
       " 217: 'потребовал',\n",
       " 218: 'военных',\n",
       " 219: 'гибели',\n",
       " 220: 'своей',\n",
       " 221: '5',\n",
       " 222: 'объявил',\n",
       " 223: 'китае',\n",
       " 224: 'выпустил',\n",
       " 225: 'нашел',\n",
       " 226: 'решил',\n",
       " 227: 'кубка',\n",
       " 228: 'саакашвили',\n",
       " 229: 'крым',\n",
       " 230: 'лнр',\n",
       " 231: 'игры',\n",
       " 232: 'признали',\n",
       " 233: 'украинский',\n",
       " 234: 'тысячи',\n",
       " 235: 'раз',\n",
       " 236: 'четыре',\n",
       " 237: 'самые',\n",
       " 238: 'миллиарда',\n",
       " 239: 'центре',\n",
       " 240: 'украина',\n",
       " 241: '1',\n",
       " 242: 'киева',\n",
       " 243: 'срок',\n",
       " 244: 'назван',\n",
       " 245: 'актер',\n",
       " 246: 'страны',\n",
       " 247: 'чм',\n",
       " 248: 'самый',\n",
       " 249: 'результате',\n",
       " 250: 'решение',\n",
       " 251: 'место',\n",
       " 252: 'работы',\n",
       " 253: 'губернатор',\n",
       " 254: 'фсб',\n",
       " 255: 'второй',\n",
       " 256: 'арестовали',\n",
       " 257: 'обвинения',\n",
       " 258: 'полиции',\n",
       " 259: 'предложила',\n",
       " 260: 'осудили',\n",
       " 261: 'оказался',\n",
       " 262: 'рост',\n",
       " 263: 'взрыва',\n",
       " 264: 'решили',\n",
       " 265: 'истории',\n",
       " 266: 'полицейских',\n",
       " 267: 'фото',\n",
       " 268: 'слова',\n",
       " 269: 'новую',\n",
       " 270: 'попытке',\n",
       " 271: 'помощи',\n",
       " 272: 'раскрыл',\n",
       " 273: 'почти',\n",
       " 274: 'как',\n",
       " 275: 'трех',\n",
       " 276: 'пообещали',\n",
       " 277: 'отказалась',\n",
       " 278: 'один',\n",
       " 279: '2',\n",
       " 280: 'главу',\n",
       " 281: 'трейлер',\n",
       " 282: 'украинских',\n",
       " 283: 'объяснили',\n",
       " 284: 'лавров',\n",
       " 285: 'сбу',\n",
       " 286: 'запретили',\n",
       " 287: '100',\n",
       " 288: 'путину',\n",
       " 289: 'заявила',\n",
       " 290: 'женщин',\n",
       " 291: 'устроили',\n",
       " 292: 'источник',\n",
       " 293: '15',\n",
       " 294: 'убийства',\n",
       " 295: 'денег',\n",
       " 296: 'умерла',\n",
       " 297: 'выборы',\n",
       " 298: 'связи',\n",
       " 299: 'навального',\n",
       " 300: 'американских',\n",
       " 301: 'помощью',\n",
       " 302: 'газа',\n",
       " 303: 'украинские',\n",
       " 304: 'путиным',\n",
       " 305: 'меркель',\n",
       " 306: 'сочи',\n",
       " 307: 'призвали',\n",
       " 308: 'россиянам',\n",
       " 309: 'правительство',\n",
       " 310: '12',\n",
       " 311: 'отношении',\n",
       " 312: 'россиянин',\n",
       " 313: 'обвинила',\n",
       " 314: 'ким',\n",
       " 315: 'я',\n",
       " 316: 'пользователей',\n",
       " 317: 'iphone',\n",
       " 318: 'apple',\n",
       " 319: 'это',\n",
       " 320: 'российским',\n",
       " 321: 'информацию',\n",
       " 322: 'тренер',\n",
       " 323: 'задержан',\n",
       " 324: 'престолов',\n",
       " 325: 'банк',\n",
       " 326: 'честь',\n",
       " 327: '30',\n",
       " 328: 'спартака',\n",
       " 329: 'рпц',\n",
       " 330: 'матча',\n",
       " 331: 'шесть',\n",
       " 332: 'жертв',\n",
       " 333: 'нефти',\n",
       " 334: 'всу',\n",
       " 335: '50',\n",
       " 336: 'пожаловался',\n",
       " 337: 'победу',\n",
       " 338: 'рекорд',\n",
       " 339: 'отказ',\n",
       " 340: 'коллекцию',\n",
       " 341: 'москва',\n",
       " 342: 'лондоне',\n",
       " 343: 'войны',\n",
       " 344: 'выборов',\n",
       " 345: 'житель',\n",
       " 346: 'опроверг',\n",
       " 347: 'пострадали',\n",
       " 348: 'ракеты',\n",
       " 349: 'полицейские',\n",
       " 350: 'сына',\n",
       " 351: 'доме',\n",
       " 352: 'убийство',\n",
       " 353: 'участие',\n",
       " 354: 'пройдет',\n",
       " 355: 'захарова',\n",
       " 356: 'причина',\n",
       " 357: 'подготовке',\n",
       " 358: 'американец',\n",
       " 359: 'идею',\n",
       " 360: 'южной',\n",
       " 361: 'китай',\n",
       " 362: 'фильма',\n",
       " 363: 'признал',\n",
       " 364: 'москву',\n",
       " 365: 'места',\n",
       " 366: 'нхл',\n",
       " 367: 'прокомментировали',\n",
       " 368: 'найден',\n",
       " 369: 'украинского',\n",
       " 370: 'отсутствии',\n",
       " 371: 'запретить',\n",
       " 372: 'японии',\n",
       " 373: 'ответил',\n",
       " 374: 'американские',\n",
       " 375: 'победы',\n",
       " 376: 'причину',\n",
       " 377: 'попросил',\n",
       " 378: 'ученые',\n",
       " 379: 'лиги',\n",
       " 380: 'северной',\n",
       " 381: 'лукашенко',\n",
       " 382: 'города',\n",
       " 383: 'боевиков',\n",
       " 384: 'данные',\n",
       " 385: 'трампом',\n",
       " 386: 'фильм',\n",
       " 387: 'возбудили',\n",
       " 388: 'белоруссии',\n",
       " 389: 'италии',\n",
       " 390: 'две',\n",
       " 391: 'свою',\n",
       " 392: 'своего',\n",
       " 393: 'великобритании',\n",
       " 394: 'участников',\n",
       " 395: 'деньги',\n",
       " 396: 'россиянина',\n",
       " 397: 'индии',\n",
       " 398: 'совфеде',\n",
       " 399: 'отставку',\n",
       " 400: 'создать',\n",
       " 401: 'госдумы',\n",
       " 402: 'сборная',\n",
       " 403: 'сочли',\n",
       " 404: 'первого',\n",
       " 405: 'упал',\n",
       " 406: 'чм-2018',\n",
       " 407: 'сообщения',\n",
       " 408: 'встречи',\n",
       " 409: 'роналду',\n",
       " 410: 'армии',\n",
       " 411: 'забил',\n",
       " 412: 'море',\n",
       " 413: 'аэропорту',\n",
       " 414: 'закон',\n",
       " 415: 'сравнил',\n",
       " 416: 'объявили',\n",
       " 417: 'испании',\n",
       " 418: 'ск',\n",
       " 419: 'цска',\n",
       " 420: 'колонии',\n",
       " 421: 'стран',\n",
       " 422: 'начал',\n",
       " 423: 'удар',\n",
       " 424: 'раскритиковал',\n",
       " 425: 'вернуть',\n",
       " 426: 'оружия',\n",
       " 427: 'фас',\n",
       " 428: '||quest_mark||',\n",
       " 429: 'министр',\n",
       " 430: 'погибших',\n",
       " 431: 'опубликовано',\n",
       " 432: 'их',\n",
       " 433: 'минфин',\n",
       " 434: 'уличили',\n",
       " 435: 'клуба',\n",
       " 436: 'предрек',\n",
       " 437: 'сделал',\n",
       " 438: 'раскрыты',\n",
       " 439: 'американского',\n",
       " 440: 'отправили',\n",
       " 441: 'оштрафовали',\n",
       " 442: 'белый',\n",
       " 443: 'список',\n",
       " 444: 'эксперты',\n",
       " 445: 'полицейского',\n",
       " 446: 'оказались',\n",
       " 447: 'дата',\n",
       " 448: 'европе',\n",
       " 449: 'жизнь',\n",
       " 450: 'соцсети',\n",
       " 451: 'матч',\n",
       " 452: 'анонсировал',\n",
       " 453: 'мэр',\n",
       " 454: 'призвала',\n",
       " 455: 'дня',\n",
       " 456: 'пост',\n",
       " 457: 'нападения',\n",
       " 458: 'раскрыта',\n",
       " 459: 'google',\n",
       " 460: 'кадыров',\n",
       " 461: 'покажут',\n",
       " 462: 'представил',\n",
       " 463: 'новом',\n",
       " 464: 'четырех',\n",
       " 465: 'взрыве',\n",
       " 466: 'facebook',\n",
       " 467: 'границе',\n",
       " 468: 'пригрозил',\n",
       " 469: 'отреагировал',\n",
       " 470: 'законопроект',\n",
       " 471: 'захарченко',\n",
       " 472: 'посла',\n",
       " 473: 'подтвердил',\n",
       " 474: 'китая',\n",
       " 475: 'около',\n",
       " 476: 'опровергли',\n",
       " 477: 'дочь',\n",
       " 478: 'курс',\n",
       " 479: 'матильды',\n",
       " 480: 'террористов',\n",
       " 481: 'автомобиль',\n",
       " 482: 'своих',\n",
       " 483: 'ввести',\n",
       " 484: 'украинской',\n",
       " 485: 'эксперт',\n",
       " 486: 'дали',\n",
       " 487: 'предрекли',\n",
       " 488: 'тюрьмы',\n",
       " 489: 'снова',\n",
       " 490: 'желании',\n",
       " 491: 'петербурга',\n",
       " 492: 'российская',\n",
       " 493: 'свой',\n",
       " 494: 'свои',\n",
       " 495: 'возможность',\n",
       " 496: 'удара',\n",
       " 497: 'поведал',\n",
       " 498: 'арест',\n",
       " 499: 'уголовное',\n",
       " 500: 'первом',\n",
       " 501: '60',\n",
       " 502: 'миллион',\n",
       " 503: 'фестиваль',\n",
       " 504: 'системы',\n",
       " 505: 'работе',\n",
       " 506: 'губернатора',\n",
       " 507: 'отношений',\n",
       " 508: 'взрыв',\n",
       " 509: 'борьбе',\n",
       " 510: 'чен',\n",
       " 511: 'аварии',\n",
       " 512: 'семь',\n",
       " 513: 'объявила',\n",
       " 514: 'чемпионата',\n",
       " 515: 'поручил',\n",
       " 516: 'создали',\n",
       " 517: 'главный',\n",
       " 518: 'кино',\n",
       " 519: 'банка',\n",
       " 520: 'восемь',\n",
       " 521: 'мутко',\n",
       " 522: 'машины',\n",
       " 523: 'модель',\n",
       " 524: 'среди',\n",
       " 525: 'вырос',\n",
       " 526: '200',\n",
       " 527: 'депутата',\n",
       " 528: 'банков',\n",
       " 529: 'памятник',\n",
       " 530: 'зенита',\n",
       " 531: 'что',\n",
       " 532: 'экономики',\n",
       " 533: 'запрет',\n",
       " 534: '2018',\n",
       " 535: 'водитель',\n",
       " 536: 'поддержку',\n",
       " 537: 'появился',\n",
       " 538: 'самым',\n",
       " 539: 'клуб',\n",
       " 540: 'футболиста',\n",
       " 541: 'признался',\n",
       " 542: 'мать',\n",
       " 543: 'акции',\n",
       " 544: 'госдума',\n",
       " 545: 'раза',\n",
       " 546: 'сообщила',\n",
       " 547: 'отказаться',\n",
       " 548: 'эфире',\n",
       " 549: 'мужчину',\n",
       " 550: 'попросили',\n",
       " 551: 'австралии',\n",
       " 552: 'полицейский',\n",
       " 553: 'попала',\n",
       " 554: '11',\n",
       " 555: 'кореи',\n",
       " 556: 'себе',\n",
       " 557: 'чиновников',\n",
       " 558: 'скорой',\n",
       " 559: 'роснефти',\n",
       " 560: 'имя',\n",
       " 561: 'женщинам',\n",
       " 562: 'допустил',\n",
       " 563: 'украинцев',\n",
       " 564: 'кроссовки',\n",
       " 565: 'прокуратура',\n",
       " 566: 'севастополе',\n",
       " 567: 'получила',\n",
       " 568: 'появились',\n",
       " 569: 'пригрозили',\n",
       " 570: 'пассажиров',\n",
       " 571: 'вороненкова',\n",
       " 572: 'вместо',\n",
       " 573: '40',\n",
       " 574: 'разрешили',\n",
       " 575: 'получили',\n",
       " 576: 'ато',\n",
       " 577: 'вопрос',\n",
       " 578: 'британский',\n",
       " 579: 'больше',\n",
       " 580: 'самых',\n",
       " 581: 'падения',\n",
       " 582: 'лучших',\n",
       " 583: 'севастополя',\n",
       " 584: 'сотрудников',\n",
       " 585: 'вновь',\n",
       " 586: 'пожаловались',\n",
       " 587: 'протеста',\n",
       " 588: 'рубля',\n",
       " 589: 'попытался',\n",
       " 590: 'произошел',\n",
       " 591: 'мир',\n",
       " 592: 'поставки',\n",
       " 593: 'продажу',\n",
       " 594: 'случае',\n",
       " 595: 'машину',\n",
       " 596: 'поймали',\n",
       " 597: 'названо',\n",
       " 598: '300',\n",
       " 599: 'выиграл',\n",
       " 600: 'зенит',\n",
       " 601: 'ввс',\n",
       " 602: 'расследование',\n",
       " 603: 'показала',\n",
       " 604: 'женщину',\n",
       " 605: 'американка',\n",
       " 606: 'the',\n",
       " 607: 'подал',\n",
       " 608: 'чемпионате',\n",
       " 609: 'пен',\n",
       " 610: 'сделать',\n",
       " 611: 'одежды',\n",
       " 612: 'ле',\n",
       " 613: 'потребовала',\n",
       " 614: 'скр',\n",
       " 615: '9',\n",
       " 616: 'московского',\n",
       " 617: 'потребовали',\n",
       " 618: 'футболу',\n",
       " 619: 'компании',\n",
       " 620: 'выхода',\n",
       " 621: 'увидел',\n",
       " 622: 'часов',\n",
       " 623: 'создал',\n",
       " 624: 'спартак',\n",
       " 625: 'хоккею',\n",
       " 626: 'цен',\n",
       " 627: 'продажи',\n",
       " 628: 'создании',\n",
       " 629: 'снял',\n",
       " 630: 'нефть',\n",
       " 631: 'соперника',\n",
       " 632: 'режим',\n",
       " 633: 'селфи',\n",
       " 634: 'мы',\n",
       " 635: 'российскую',\n",
       " 636: 'мяч',\n",
       " 637: 'сын',\n",
       " 638: 'суда',\n",
       " 639: 'открыли',\n",
       " 640: 'эрдоган',\n",
       " 641: 'жириновский',\n",
       " 642: 'проект',\n",
       " 643: 'условие',\n",
       " 644: 'собой',\n",
       " 645: 'иран',\n",
       " 646: 'месси',\n",
       " 647: 'несколько',\n",
       " 648: 'пьяный',\n",
       " 649: 'посоветовал',\n",
       " 650: 'бренд',\n",
       " 651: 'пожаре',\n",
       " 652: 'сбербанк',\n",
       " 653: 'вышли',\n",
       " 654: 'дату',\n",
       " 655: 'отреагировали',\n",
       " 656: 'атаки',\n",
       " 657: 'пожар',\n",
       " 658: 'намерении',\n",
       " 659: 'жители',\n",
       " 660: 'безопасности',\n",
       " 661: 'нью-йорке',\n",
       " 662: 'избили',\n",
       " 663: 'наса',\n",
       " 664: 'чемпионов',\n",
       " 665: '2016',\n",
       " 666: 'цены',\n",
       " 667: 'белого',\n",
       " 668: 'встрече',\n",
       " 669: '8',\n",
       " 670: 'подписал',\n",
       " 671: 'лидер',\n",
       " 672: 'заявление',\n",
       " 673: 'двое',\n",
       " 674: 'порно',\n",
       " 675: 'журналист',\n",
       " 676: 'мировой',\n",
       " 677: 'трампу',\n",
       " 678: 'борьбы',\n",
       " 679: 'оружие',\n",
       " 680: 'турция',\n",
       " 681: 'ножом',\n",
       " 682: 'устроил',\n",
       " 683: 'хакеры',\n",
       " 684: 'таиланде',\n",
       " 685: 'собчак',\n",
       " 686: 'мединский',\n",
       " 687: 'шарапова',\n",
       " 688: 'десять',\n",
       " 689: 'фбр',\n",
       " 690: 'автобуса',\n",
       " 691: 'детьми',\n",
       " 692: 'выступил',\n",
       " 693: 'крае',\n",
       " 694: 'автор',\n",
       " 695: '18',\n",
       " 696: 'иск',\n",
       " 697: 'савченко',\n",
       " 698: 'украиной',\n",
       " 699: 'ufc',\n",
       " 700: 'емельяненко',\n",
       " 701: 'вконтакте',\n",
       " 702: 'журналиста',\n",
       " 703: 'отель',\n",
       " 704: 'автомобилей',\n",
       " 705: 'условия',\n",
       " 706: 'женщина',\n",
       " 707: 'задержании',\n",
       " 708: 'одежду',\n",
       " 709: '14',\n",
       " 710: 'боец',\n",
       " 711: 'депутаты',\n",
       " 712: 'чемпион',\n",
       " 713: 'самой',\n",
       " 714: 'мигрантов',\n",
       " 715: 'польше',\n",
       " 716: 'мгу',\n",
       " 717: 'чечне',\n",
       " 718: 'матвиенко',\n",
       " 719: 'продали',\n",
       " 720: 'сеть',\n",
       " 721: '7',\n",
       " 722: 'евровидения',\n",
       " 723: 'земли',\n",
       " 724: 'директор',\n",
       " 725: 'прямом',\n",
       " 726: 'уильямс',\n",
       " 727: 'попытку',\n",
       " 728: 'cnn',\n",
       " 729: 'группы',\n",
       " 730: 'сотни',\n",
       " 731: 'депутатов',\n",
       " 732: 'польши',\n",
       " 733: 'переговоров',\n",
       " 734: 'корее',\n",
       " 735: 'причиной',\n",
       " 736: 'следователи',\n",
       " 737: 'команды',\n",
       " 738: '16',\n",
       " 739: 'задумались',\n",
       " 740: 'уволили',\n",
       " 741: '4',\n",
       " 742: 'предложение',\n",
       " 743: 'конфедераций',\n",
       " 744: 'насмерть',\n",
       " 745: 'выросло',\n",
       " 746: 'первые',\n",
       " 747: 'ему',\n",
       " 748: 'слухи',\n",
       " 749: 'ракет',\n",
       " 750: 'угрозой',\n",
       " 751: 'отдыха',\n",
       " 752: 'саудовской',\n",
       " 753: 'вертолета',\n",
       " 754: 'цру',\n",
       " 755: 'встречу',\n",
       " 756: 'урагана',\n",
       " 757: 'ситуацию',\n",
       " 758: 'свое',\n",
       " 759: 'пообещала',\n",
       " 760: 'российском',\n",
       " 761: 'бой',\n",
       " 762: 'прав',\n",
       " 763: 'обыграл',\n",
       " 764: 'серебренникова',\n",
       " 765: 'тело',\n",
       " 766: 'военного',\n",
       " 767: 'мужчин',\n",
       " 768: 'школьников',\n",
       " 769: 'каталонии',\n",
       " 770: 'открыл',\n",
       " 771: 'мальчика',\n",
       " 772: 'государства',\n",
       " 773: 'счел',\n",
       " 774: 'компания',\n",
       " 775: 'instagram',\n",
       " 776: 'девять',\n",
       " 777: 'проверку',\n",
       " 778: 'возле',\n",
       " 779: 'оказалась',\n",
       " 780: 'лидера',\n",
       " 781: 'соцсетях',\n",
       " 782: 'выпустила',\n",
       " 783: 'задержала',\n",
       " 784: 'стоимость',\n",
       " 785: 'провести',\n",
       " 786: 'одного',\n",
       " 787: 'въезд',\n",
       " 788: 'американской',\n",
       " 789: 'премии',\n",
       " 790: '3',\n",
       " 791: 'машин',\n",
       " 792: 'напал',\n",
       " 793: 'мчс',\n",
       " 794: 'анонсировали',\n",
       " 795: 'фанаты',\n",
       " 796: 'парламент',\n",
       " 797: 'киргизии',\n",
       " 798: 'лучший',\n",
       " 799: 'сбил',\n",
       " 800: 'женщины',\n",
       " 801: 'закона',\n",
       " 802: 'роли',\n",
       " 803: 'приговор',\n",
       " 804: 'возможности',\n",
       " 805: 'выпустили',\n",
       " 806: 'игрок',\n",
       " 807: 'переговоры',\n",
       " 808: 'стороны',\n",
       " 809: 'раскрыли',\n",
       " 810: 'состоянии',\n",
       " 811: 'лучшие',\n",
       " 812: 'предупредили',\n",
       " 813: 'авиакомпания',\n",
       " 814: 'голову',\n",
       " 815: 'лицо',\n",
       " 816: 'новым',\n",
       " 817: 'клип',\n",
       " 818: 'сезона',\n",
       " 819: 'а',\n",
       " 820: 'париже',\n",
       " 821: 'угрозы',\n",
       " 822: 'госдеп',\n",
       " 823: 'рогозин',\n",
       " 824: 'гражданства',\n",
       " 825: 'шойгу',\n",
       " 826: 'поезд',\n",
       " 827: 'макрона',\n",
       " 828: 'предсказал',\n",
       " 829: 'смерть',\n",
       " 830: 'строительство',\n",
       " 831: 'станет',\n",
       " 832: 'боя',\n",
       " 833: 'подозреваемых',\n",
       " 834: 'воробьев',\n",
       " 835: 'орешкин',\n",
       " 836: 'выразил',\n",
       " 837: 'донбасс',\n",
       " 838: 'центр',\n",
       " 839: 'миллиард',\n",
       " 840: 'американцы',\n",
       " 841: 'эвакуировали',\n",
       " 842: 'русских',\n",
       " 843: 'город',\n",
       " 844: 'манчестер',\n",
       " 845: 'десятки',\n",
       " 846: 'фанатов',\n",
       " 847: 'дочери',\n",
       " 848: 'журналистов',\n",
       " 849: 'telegram',\n",
       " 850: 'директора',\n",
       " 851: 'развития',\n",
       " 852: 'марта',\n",
       " 853: 'поезда',\n",
       " 854: 'фифа',\n",
       " 855: 'совет',\n",
       " 856: 'производство',\n",
       " 857: 'пожара',\n",
       " 858: 'вкс',\n",
       " 859: 'теракте',\n",
       " 860: 'избил',\n",
       " 861: 'украли',\n",
       " 862: 'фрг',\n",
       " 863: 'случайно',\n",
       " 864: 'доллара',\n",
       " 865: 'армия',\n",
       " 866: 'аравии',\n",
       " 867: 'вышла',\n",
       " 868: 'появится',\n",
       " 869: 'шоу',\n",
       " 870: 'состав',\n",
       " 871: 'марка',\n",
       " 872: 'подозреваемого',\n",
       " 873: 'части',\n",
       " 874: 'граждан',\n",
       " 875: 'неизвестные',\n",
       " 876: 'учителя',\n",
       " 877: 'песню',\n",
       " 878: 'большой',\n",
       " 879: 'решила',\n",
       " 880: 'биатлону',\n",
       " 881: 'выиграла',\n",
       " 882: 'ударом',\n",
       " 883: 'московской',\n",
       " 884: 'газета',\n",
       " 885: 'кличко',\n",
       " 886: 'тренера',\n",
       " 887: 'ссср',\n",
       " 888: 'актера',\n",
       " 889: 'наркотиков',\n",
       " 890: 'рейтинг',\n",
       " 891: 'белом',\n",
       " 892: 'стать',\n",
       " 893: 'ирана',\n",
       " 894: 'попросила',\n",
       " 895: 'попытались',\n",
       " 896: 'понадеялся',\n",
       " 897: 'ходе',\n",
       " 898: 'главе',\n",
       " 899: 'одобрил',\n",
       " 900: 'антироссийских',\n",
       " 901: 'помощь',\n",
       " 902: 'факту',\n",
       " 903: 'нашла',\n",
       " 904: 'премию',\n",
       " 905: 'версию',\n",
       " 906: 'собрался',\n",
       " 907: 'поклонская',\n",
       " 908: 'туристы',\n",
       " 909: 'американцев',\n",
       " 910: 'беженцев',\n",
       " 911: 'превратили',\n",
       " 912: 'лучшим',\n",
       " 913: 'open',\n",
       " 914: 'узнал',\n",
       " 915: 'стрелка',\n",
       " 916: 'рфпл',\n",
       " 917: 'девочки',\n",
       " 918: 'воду',\n",
       " 919: 'учения',\n",
       " 920: 'главного',\n",
       " 921: 'солдат',\n",
       " 922: 'конца',\n",
       " 923: 'московском',\n",
       " 924: 'операции',\n",
       " 925: 'поддержал',\n",
       " 926: 'задержаны',\n",
       " 927: 'соглашение',\n",
       " 928: 'часть',\n",
       " 929: 'сизо',\n",
       " 930: 'дать',\n",
       " 931: 'моста',\n",
       " 932: 'первой',\n",
       " 933: '6',\n",
       " 934: 'режиссер',\n",
       " 935: 'данных',\n",
       " 936: 'запретил',\n",
       " 937: 'министра',\n",
       " 938: 'отмены',\n",
       " 939: 'посол',\n",
       " 940: 'звезда',\n",
       " 941: 'раскритиковали',\n",
       " 942: 'стрельбы',\n",
       " 943: 'пентагон',\n",
       " 944: 'отца',\n",
       " 945: 'ответили',\n",
       " 946: 'права',\n",
       " 947: 'адрес',\n",
       " 948: 'рф',\n",
       " 949: 'первую',\n",
       " 950: 'конфликта',\n",
       " 951: 'военной',\n",
       " 952: 'представила',\n",
       " 953: 'узнала',\n",
       " 954: 'сирию',\n",
       " 955: 'своем',\n",
       " 956: 'wada',\n",
       " 957: 'столкновения',\n",
       " 958: 'роста',\n",
       " 959: 'главная',\n",
       " 960: 'кубани',\n",
       " 961: 'участия',\n",
       " 962: 'рождения',\n",
       " 963: 'быть',\n",
       " 964: 'партии',\n",
       " 965: 'клинтон',\n",
       " 966: 'премьер',\n",
       " 967: 'тела',\n",
       " 968: 'причины',\n",
       " 969: 'назад',\n",
       " 970: 'жителя',\n",
       " 971: 'треть',\n",
       " 972: 'воды',\n",
       " 973: 'арестован',\n",
       " 974: 'необходимости',\n",
       " 975: 'спасли',\n",
       " 976: 'зарплаты',\n",
       " 977: 'пяти',\n",
       " 978: 'обсе',\n",
       " 979: '13',\n",
       " 980: 'неизвестный',\n",
       " 981: 'застрелили',\n",
       " 982: 'чемпиона',\n",
       " 983: 'брата',\n",
       " 984: 'дети',\n",
       " 985: 'запрете',\n",
       " 986: 'опасность',\n",
       " 987: 'терактов',\n",
       " 988: '17',\n",
       " 989: 'g20',\n",
       " 990: 'потери',\n",
       " 991: 'военный',\n",
       " 992: 'газпром',\n",
       " 993: 'сирийской',\n",
       " 994: 'километров',\n",
       " 995: 'возвращения',\n",
       " 996: 'нас',\n",
       " 997: 'фонд',\n",
       " 998: 'домогательствах',\n",
       " 999: 'подростков',\n",
       " ...}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Строим нейронную сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Входные данные\n",
    "Функция `get_inputs()` создает набор TensorFlow Placeholder для нейронной сети:\n",
    "- Плейсхолдер с названием `input` для входного текста, используя параметр `name` для [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder);\n",
    "- Плейсхолдер для целевых значений\n",
    "- Плейсхолдер для Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"input\")\n",
    "    targets = tf.placeholder(tf.int32, shape=[None, None], name=\"targets\")\n",
    "    l_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    \n",
    "    return inputs, targets, l_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Строим и инициализируем рекуррентные ячейки\n",
    "Заполняем [`MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell) одним или несколькими [`BasicLSTMCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell).\n",
    "- `rnn_size` задает количество ячеек;\n",
    "- `num_layers` задает количество рекуррентных слоев;\n",
    "- функция [`zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state) из MultiRNNCell инициализирует начальное состояние;\n",
    "- `get_init_cell` возвращает набор слоев в виде MultiRNNCell и начальное состояние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_init_cell(batch_size, rnn_size, num_layers=2, dropout=0.1):\n",
    "    basic_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    basic_cell_with_dropout = tf.contrib.rnn.DropoutWrapper(basic_cell, output_keep_prob=(1-dropout))\n",
    "    multi_rnn_cell = tf.contrib.rnn.MultiRNNCell([basic_cell_with_dropout] * num_layers)\n",
    "    init_state = tf.identity(multi_rnn_cell.zero_state(batch_size, tf.float32), name=\"initial_state\")\n",
    "\n",
    "    return multi_rnn_cell, init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Embedding\n",
    "Собственно, создание Word Embedding. Функция возвращает эмбеддинг для `input_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "    \n",
    "    return tf.nn.embedding_lookup(embedding, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Строим рекуррентный слой\n",
    "Из ячейки, созданной с помощью `get_init_cell()` строим рекуррентный слой. Функция выдает выходные значения после прогона данных через RNN, и состояние слоя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "    final_state = tf.identity(final_state, name=\"final_state\")\n",
    "    \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Собираем сеть\n",
    "Применяем реализованные выше функции:\n",
    "- Создаем эмбеддинги из `input_data`, используя `get_embed(input_data, vocab_size, embed_dim)`;\n",
    "- Передаем из в рекуррентный слой `build_rnn(cell, inputs)`;\n",
    "- Применяем fully connected слой с линейной активацией, передавая результаты из рекуррентного слоя и `vocab_size` в качестве размерности выходного значения.\n",
    "\n",
    "В результате возвращаются logits и финальное состояние сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size):\n",
    "    \n",
    "    inputs = get_embed(input_data, vocab_size, rnn_size)\n",
    "    outputs, final_state = build_rnn(cell, inputs)\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, num_outputs=vocab_size, activation_fn=None)\n",
    "    \n",
    "    return logits, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Батчи\n",
    "Функция `get_batches` создает батчи из входного текста `int_text`.  Каждый батч - `Numpy array` с размерностями `(количество батчей, 2, размер батча, длина последовательности)`. Каждый батч содержит два элемента:\n",
    "- Первый элемент - батч входных значений размерности `[размер батча, длина последовательности]`\n",
    "- Второй элемент - батч целевых значений размерности `[размер батча, длина последовательности]`\n",
    "\n",
    "Если для последнего батча недостаточно данных, отбрасываем его.\n",
    "\n",
    "Например, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)` вернет следующий массив:\n",
    "```\n",
    "[\n",
    "  # Первый батч\n",
    "  [\n",
    "    # Батч входных значений\n",
    "    [[ 1  2  3], [ 7  8  9]],\n",
    "    # Батч целевых значений\n",
    "    [[ 2  3  4], [ 8  9 10]]\n",
    "  ],\n",
    " \n",
    "  # Второй батч\n",
    "  [\n",
    "    # Батч входных значений\n",
    "    [[ 4  5  6], [10 11 12]],\n",
    "    # Батч целевых значений\n",
    "    [[ 5  6  7], [11 12 13]]\n",
    "  ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "\n",
    "    num_batches = len(int_text) // (batch_size * seq_length)\n",
    "    batches = []\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        inputs=[]\n",
    "        targets=[]\n",
    "        \n",
    "        for seq_idx in range(batch_size):\n",
    "            i = batch_idx * seq_length + seq_idx * seq_length\n",
    "            inputs.append(int_text[i:i+seq_length])\n",
    "            targets.append(int_text[i+1: i+seq_length+1])\n",
    "        \n",
    "        batches.append([inputs, targets])\n",
    "    \n",
    "    return np.array(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Вспомогательные функции\n",
    "### Загрузка тензоров\n",
    "Загружаем тензоры из `loaded_graph`, используя [`get_tensor_by_name()`](https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "\n",
    "    inputs = loaded_graph.get_tensor_by_name('input:0')\n",
    "    initial_state = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    final_state = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    probs = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    \n",
    "    return inputs, initial_state, final_state, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Выбор слова\n",
    "Функция `pick_word()` выбирает следующее слово на основе вероятностей в `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "\n",
    "    return int_to_vocab[np.argmax(probabilities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Список первых слов\n",
    "Составляем список первых слов заголовков. Будем использовать их в качестве входного значения для генерации заголовка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "first_words = list(set([line.split(\" \")[0] for line in text.split('. ')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Генерация заголовка\n",
    "Функция загружает граф, восстанавливает сессию и возвращает сгенерированную последовательность слов. Параметры:\n",
    "- `get_length`: длина генерируемой последовательности (сколько слов нужно сгенерировать);\n",
    "- `prime_word`: начальное (входное) слово для генерации;\n",
    "- `load_dir`: первая часть названия файла с графом;\n",
    "- `rnn_layers`: количество слоев (используется только для построения имени файла);\n",
    "- `rnn_size`: размер слоев (используется только для построения имени файла)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def infer(gen_length, prime_word, load_dir, rnn_layers, rnn_size):\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        \n",
    "        # Загружаем модель\n",
    "        loader = tf.train.import_meta_graph(load_dir +'_{}_{}.meta'.format(rnn_layers, rnn_size) )\n",
    "        loader.restore(sess, load_dir +'_{}_{}'.format(rnn_layers, rnn_size))\n",
    "\n",
    "        # Получаем тензоры из модели\n",
    "        input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "        # Инициализируем переменную, где будем хранить сгенерированную последовательность\n",
    "        gen_sentences = [prime_word]\n",
    "    \n",
    "        prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "        # Генерация последовательности\n",
    "        for n in range(gen_length):\n",
    "            \n",
    "            dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "            dyn_seq_length = len(dyn_input[0])\n",
    "    \n",
    "            # Получаем вероятности\n",
    "            probabilities, prev_state = sess.run(\n",
    "                [probs, final_state],\n",
    "                {input_text: dyn_input, initial_state: prev_state})\n",
    "    \n",
    "            # Получаем следующее слово\n",
    "            pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab)\n",
    "            gen_sentences.append(pred_word)\n",
    "\n",
    "        # Удаляем токены пунктуации, заменяя их на соответствующие символы\n",
    "        headlines = ' '.join(gen_sentences)\n",
    "        for key, token in token_dict.items():\n",
    "            ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "            headlines = headlines.replace(' ' + token.lower(), key)\n",
    "        headlines = headlines.replace('\\n ', '\\n')\n",
    "        headlines = headlines.replace('( ', '(')\n",
    "        headlines = headlines.replace('. ', '.\\n')\n",
    "                \n",
    "        print(headlines)\n",
    "        return headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Обучение нейронной сети\n",
    "### Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Количество эпох (итераций обучения)\n",
    "num_epochs = 20\n",
    "\n",
    "# Размер батча\n",
    "batch_size = 32\n",
    "\n",
    "# Размер рекуррентного слоя\n",
    "# rnn_size = 64\n",
    "\n",
    "# Длина последовательности в батче, определяет как далеко \"назад\" сеть должна помнить контекст\n",
    "seq_length = 10\n",
    "\n",
    "# Скорость обучения\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Выводить статистику через каждые N батчей\n",
    "show_every_n_batches = 500\n",
    "\n",
    "# Длина генерируемой последовательности\n",
    "gen_length = 100\n",
    "\n",
    "# массив опций для обучения; используется для того, чтобы определить наиболее удачную конфигурацию нейронной сети; \n",
    "# для обучения только по одному набору параметров, можно закомментировать остальные наборы\n",
    "options = [\n",
    "#     {\n",
    "#         'rnn_size': 32,\n",
    "#         'rnn_layers': 1\n",
    "#     },\n",
    "    {\n",
    "        'rnn_size': 64,\n",
    "        'rnn_layers': 1\n",
    "    },\n",
    "#     {\n",
    "#         'rnn_size': 32,\n",
    "#         'rnn_layers': 2\n",
    "#     },\n",
    "#     {\n",
    "#         'rnn_size': 64,\n",
    "#         'rnn_layers': 2\n",
    "#     }\n",
    "]\n",
    "\n",
    "# Первая часть названия файла модели\n",
    "save_dir = './models/word_emb_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Обучение\n",
    "Фиксируем первое слово для всех итераций, чтобы сравнивать результаты генерации. Затем проходимся по всем конфигурациям и обучаем сеть, попутно выводя промежуточные результаты и сохраняя их в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели Word Embeddings с параметрами (слои: 1, размер: 64)\n",
      "Итерация   0 Батч    0/1630   train_loss = 11.125                                                   \n",
      "Итерация   0 Батч  500/1630   train_loss = 3.225                                                    \n",
      "Итерация   0 Батч 1000/1630   train_loss = 3.111                                                    \n",
      "Итерация   0 Батч 1500/1630   train_loss = 3.384                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 9:25:25 \n",
      "Сгенерированный текст для итерации 0:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома.\n",
      "попал в сети во вселенной.\n",
      "тесак получил 10 из сша.\n",
      "трех отсутствие антивещества во вселенной.\n",
      "тесак получил 10 10 лет колонии.\n",
      "макрон пригласил трампа в париж.\n",
      "распространители вируса petya просчитались от поездки на прощание с колем.\n",
      "минимальный набор продуктов с шантажом.\n",
      "сша заявили о связях советника трампа в париж.\n",
      "распространители petya просчитались с шантажом.\n",
      "g-shock устроил пацанскую тусовку энциклопедии.\n",
      "семья обамы прокатилась по в россии.\n",
      "подушкой в дзюба днр из багажа на ответ.\n",
      "после шести лет колонии.\n",
      "макрон пригласил трампа в париж.\n",
      "распространители с колем\n",
      "Итерация   1 Батч  370/1630   train_loss = 2.080                                                    \n",
      "Итерация   1 Батч  870/1630   train_loss = 1.514                                                    \n",
      "Итерация   1 Батч 1370/1630   train_loss = 1.302                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 8:51:57 \n",
      "Сгенерированный текст для итерации 1:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома telegram за заключение.\n",
      "в кремле сочли недопустимым отсутствие прогресса в нормализации отношений с сша.\n",
      "в мире лет.\n",
      "слуцкий указал пасе на ведущую в тупик русофобию.\n",
      "найдена новая опасность солнцезащитных кремов.\n",
      "врачи отговорили горбачева от поездки на прощание сша путина на уличенного в сборную сборную умер в подготовке здания суда российский лесного руководство получил необходимые госдумы.\n",
      "девять к джоплин виртуальному возлюбленному.\n",
      "эмоции следствие назвало две версии обрушения облил кислотой трех девочек.\n",
      "названы встречи с сша на уличенного в рассылке порно девочкам жителя череповца завели девять дел.\n",
      "иркутский электрик застрелил задолжавшего ему главу\n",
      "Итерация   2 Батч  240/1630   train_loss = 1.137                                                    \n",
      "Итерация   2 Батч  740/1630   train_loss = 1.142                                                    \n",
      "Итерация   2 Батч 1240/1630   train_loss = 0.954                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 8:31:28 \n",
      "Сгенерированный текст для итерации 2:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома посада ракетка, чем такое до 72 лет колонии.\n",
      "макрон пригласил трампа в париж.\n",
      "распространители определены, сша рассказал о попытках на попытках спецслужб повлиять на внутренние дела россии.\n",
      "семь человек.\n",
      "после рынок на сирийские переговоры с колем.\n",
      "минимальный набор продуктов в россии резко подорожал.\n",
      "национализированного уровнем выдали трансгендеру анатомия под убить сша в.\n",
      "в севастополе.\n",
      "иркутский электрик застрелил задолжавшего ему главу агентства недвижимости.\n",
      "фсин фонд систему новом сняли журналистов cnn отправил греческую принцессу за счет российских туристов в доминикане выросло на 300 процентов.\n",
      "кандидатов в губернаторы призвали провериться на\n",
      "Итерация   3 Батч  110/1630   train_loss = 0.666                                                    \n",
      "Итерация   3 Батч  610/1630   train_loss = 0.811                                                    \n",
      "Итерация   3 Батч 1110/1630   train_loss = 0.749                                                    \n",
      "Итерация   3 Батч 1610/1630   train_loss = 0.721                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 13:51:26 \n",
      "Сгенерированный текст для итерации 3:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома уровнем епископа задержали в подмосковье величества на данных в продолжении tor.\n",
      "в москве ответили на заявление на процентов.\n",
      "предложил матерям-одиночкам альтернативу беби-боксам покинуть раскрасил в россии.\n",
      "эмоции посетителей мфц оценит специальная программа.\n",
      "словарь попал в подмосковье на уличенного в искусственном гнезде погибли пять человек.\n",
      "на сирийские переговоры под контролем отставку в области области спровоцировал дтп с сохатый ему главу агентства недвижимости.\n",
      "емельяненко, выпускной на 185.\n",
      "в подмосковье учредили премию живу макрона потребовали журналистов cnn уволили пользователи.\n",
      "панда спихнула помешавшего есть бамбук детеныша со склона.\n",
      "силуанов посулил россиянам рост реальных доходов\n",
      "Итерация   4 Батч  480/1630   train_loss = 0.588                                                    \n",
      "Итерация   4 Батч  980/1630   train_loss = 0.588                                                    \n",
      "Итерация   4 Батч 1480/1630   train_loss = 0.585                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 11:45:24 \n",
      "Сгенерированный текст для итерации 4:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома делу под.\n",
      "выпрыгнувший в честь сталина.\n",
      "0 apple путину о произволе.\n",
      "историю 2 бондарчука и еще 15 российских фильмов.\n",
      "американских журналистов обокрали в черногории.\n",
      "в кино престолов.\n",
      "названы журналистов не фиг.\n",
      "округ леттланд.\n",
      "онкологи в москве выдали покинуть водопой.\n",
      "в кремле пообещали жесткую лет об интервью.\n",
      "скр возбудил дело в подготовке химатаки.\n",
      "в россии резко ужесточить наказание за украине предупредили о подготовке химатаки в сирии.\n",
      "эксперт рассказал похвалилась на большой двадцатке убийц олеся бузины.\n",
      "вышел в число российских туристов сша в подмосковье redken.\n",
      "французские жандармы признали\n",
      "Итерация   5 Батч  350/1630   train_loss = 0.457                                                    \n",
      "Итерация   5 Батч  850/1630   train_loss = 0.597                                                    \n",
      "Итерация   5 Батч 1350/1630   train_loss = 0.528                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 10:11:10 \n",
      "Сгенерированный текст для итерации 5:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома саудовская аравия решила побороться с холерой в йемене.\n",
      "выигравшая миллион иску в париж.\n",
      "путин встретится с бывшим госсекретарем петербурге.\n",
      "эксперт рассказал с лет.\n",
      "слуцкий назвал тупиковым решение ес продлить санкции ес против россии.\n",
      "скандал пассажиров продлить санкции против россии.\n",
      "в отметили ажиотажный спрос на автомобили jaguar.\n",
      "deichmann обует девочек петербурга в анталью.\n",
      "продюсер cnn раскрыл причину обилия фейковых новостей о россии.\n",
      "тиньков назвал оценил ежегодные инвестиции сочли о блокировке сняли мемориальную доску маршалу жукову в одессе.\n",
      "команда аналитиков втб капитала признана лучшей в 14 путину завлечь трампа посетить индию.\n",
      "Итерация   6 Батч  220/1630   train_loss = 0.423                                                    \n",
      "Итерация   6 Батч  720/1630   train_loss = 0.361                                                    \n",
      "Итерация   6 Батч 1220/1630   train_loss = 0.302                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 8:53:29 \n",
      "Сгенерированный текст для итерации 6:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома преемника двух фрегатов типа за следствие предложили путина на большой двадцатке.\n",
      "16-летний чемпион по спортивному ориентированию аравия решила побороться с холерой в йемене.\n",
      "выигравшая миллион ради 1000 рока россиян.\n",
      "госдеп хане автомобилей москва миллион долларов.\n",
      "американский солдат пригласил трампа посетить кислоту.\n",
      "столкновении строительства россии.\n",
      "тиньков назвал дурова быдлом и публично стер telegram с iphone.\n",
      "на уличенного в рассылке порно девочкам жителя череповца завели девять дел сша.\n",
      "кота сша и личностью.\n",
      "семья обамы прокатилась из-за минимальный набор продуктов в россии резко подорожал.\n",
      "глава национализированного украиной приватбанка попросился в отставку.\n",
      "генсек\n",
      "Итерация   7 Батч   90/1630   train_loss = 0.534                                                    \n",
      "Итерация   7 Батч  590/1630   train_loss = 0.521                                                    \n",
      "Итерация   7 Батч 1090/1630   train_loss = 0.414                                                    \n",
      "Итерация   7 Батч 1590/1630   train_loss = 0.276                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 7:48:09 \n",
      "Сгенерированный текст для итерации 7:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома за власти обвинения в дтп.\n",
      "беда для спортивного для объявила о получении взятки.\n",
      "бьюти-директор estee lauder назвала необходимую обвинил клинтон в сговоре на кибератаки.\n",
      "граната под подушкой.\n",
      "в кремле появилось рассказали о боец martin россия трампа с лодкой горбатый кит попал.\n",
      "сын екатеринбурге у пассажирам запретить у уильямс заживо в россии.\n",
      "макрон пригласил трампа в париж.\n",
      "распространители вируса petya просчитались с шантажом.\n",
      "g-shock устроил пацанскую тусовку в дк зил.\n",
      "девять друзей тесака.\n",
      "в кремле пообещали рассказать путину ответили на спутниками связи.\n",
      "лавров пообещал украиной.\n",
      "силуанов посулил россиянам рост\n",
      "Итерация   8 Батч  460/1630   train_loss = 0.496                                                    \n",
      "Итерация   8 Батч  960/1630   train_loss = 0.539                                                    \n",
      "Итерация   8 Батч 1460/1630   train_loss = 0.398                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 6:51:47 \n",
      "Сгенерированный текст для итерации 8:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома саудовская долларов за неделю миллиона долларов.\n",
      "драчливых охранников эрдогана не пустят на лето.\n",
      "определились полуфинальные пары кубка конфедераций.\n",
      "выбросившаяся пляж задумались на четыре иностранца.\n",
      "в россию из балашихи.\n",
      "в таиланде разоблачили банду угонщиков суперкаров жиркову сочли донбассе.\n",
      "следствие назвало две версии обрушения в уволили из-за статьи о связях советника трампа в париж.\n",
      "распространители бывший помидоров.\n",
      "путин встретится с бывшим госсекретарем сша.\n",
      "на ямале кречеты впервые вывели потомство в искусственном гнезде.\n",
      "имение из рук участников сериала солдаты заслуженной артисткой россии.\n",
      "в тренировке в юнармию.\n",
      "москве возбуждено уголовное дело о\n",
      "Итерация   9 Батч  330/1630   train_loss = 0.459                                                    \n",
      "Итерация   9 Батч  830/1630   train_loss = 0.473                                                    \n",
      "Итерация   9 Батч 1330/1630   train_loss = 0.340                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 6:01:41 \n",
      "Сгенерированный текст для итерации 9:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома саудовская аравия в чм очередной уткой неугомонных англичан об дороги инновационные r2-d2 из звездных войн продали на аукционе.\n",
      "присяжные удалились для вынесения вердикта по делу об убийстве трампа.\n",
      "названы самые распространенные наркотики над российском tor.\n",
      "в кино porsche оценили в 16 миллионов.\n",
      "россии предложил дать в отказе дамаска от химатаки из-за предупреждений пентагона.\n",
      "депутат лебедев признал наказания.\n",
      "президент киргизии открылась проекта имущество макрона в проекту белого зрителей через россию.\n",
      "сми узнали о возможном новом владельце российского forbes.\n",
      "фильм 28 панфиловцев стал лауреатом кинофестиваля беженцев новую сложнее прилично шутить о россии слова об\n",
      "Итерация  10 Батч  200/1630   train_loss = 0.433                                                    \n",
      "Итерация  10 Батч  700/1630   train_loss = 0.375                                                    \n",
      "Итерация  10 Батч 1200/1630   train_loss = 0.338                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 5:16:51 \n",
      "Сгенерированный текст для итерации 10:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома над балтикой.\n",
      "дочка шоколадницы, связях оплачиваемые неофисные профессии в россии.\n",
      "для у берегов ливии нашли тела 24 первый.\n",
      "центр санкции в против россии отметили ажиотажный спрос на автомобили jaguar.\n",
      "deichmann обует девочек.\n",
      "названы авианосец россии и стал любимцем заморозил создание на краснодар к виртуальному возлюбленному отметили ажиотажный спрос на автомобили jaguar.\n",
      "deichmann обует девочек одного указал в балета.\n",
      "полиция на сочи на замерла на уровне 0,, 1 процента.\n",
      "минэкономразвития дтп попал на видео и прачечной.\n",
      "названы самые распространенные наркотики в российском tor.\n",
      "в сша потребовали запретить военным\n",
      "Итерация  11 Батч   70/1630   train_loss = 0.404                                                    \n",
      "Итерация  11 Батч  570/1630   train_loss = 0.426                                                    \n",
      "Итерация  11 Батч 1070/1630   train_loss = 0.424                                                    \n",
      "Итерация  11 Батч 1570/1630   train_loss = 0.390                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 4:35:16 \n",
      "Сгенерированный текст для итерации 11:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома власти на ямале кречеты.\n",
      "pompeya на главной сцене усадьбы jazz новая.\n",
      "прессы о переломе позвоночника у этуша.\n",
      "путин поздравил выпускников с сша от отдыха в индонезии.\n",
      "из-за лесного пожара в испании эвакуированы 1800 человек.\n",
      "милости просим.\n",
      "такси залога киргизии ответили над хабаровском.\n",
      "руки немцова.\n",
      "норвежцы начали подготовку расчетов для модернизированных ракет atacms.\n",
      "завершилось расследование уголовного дела об человек.\n",
      "российских инфляция в кндр образцовой.\n",
      "взрыв россии в просчитались с шантажом.\n",
      "g-shock устроил пацанскую тусовку загранпаспорт ее колонии в сирии.\n",
      "и ираке похвалил блокчейн.\n",
      "из-за лесного пожара в\n",
      "Итерация  12 Батч  440/1630   train_loss = 0.353                                                    \n",
      "Итерация  12 Батч  940/1630   train_loss = 0.453                                                    \n",
      "Итерация  12 Батч 1440/1630   train_loss = 0.401                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 3:55:59 \n",
      "Сгенерированный текст для итерации 12:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома пассажиров похвалил.\n",
      "истории ленинграда.\n",
      "в подмосковье пообещал скорое возвращение в сладкую обувь.\n",
      "названы сроки открытия станции московского метро подало.\n",
      "фонд кино профинансирует притяжение 2.\n",
      "мигрант за блокировки от процедуру поступления на снимавших фильм 28 панфиловцев стал лауреатом кинофестиваля кадровые пасе на бой мэйуэзера на металлолом пожарную машину саратовского рд-180.\n",
      "выпускной в первый же день призвавшего.\n",
      "на хвосты.\n",
      "французские жандармы арестовали.\n",
      "иэн из швеции после неонацистскими целей.\n",
      "макрон пригласил трампа в российском причину сирийские дела россии.\n",
      "власти республики сербской посмертно наградили виталия чуркина орденом.\n",
      "путин встретится с бывшим госсекретарем\n",
      "Итерация  13 Батч  310/1630   train_loss = 0.458                                                    \n",
      "Итерация  13 Батч  810/1630   train_loss = 0.444                                                    \n",
      "Итерация  13 Батч 1310/1630   train_loss = 0.437                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 3:18:39 \n",
      "Сгенерированный текст для итерации 13:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома урганта.\n",
      "на кубка конфедераций.\n",
      "росэнергобанк признали банкротом.\n",
      "обругавший акинфеева депутат усомнился в шансах украины на самолет в стал лауреатом кинофестиваля имиджа сша в ле-бурже гражданский боевикам нато иг в сирии.\n",
      "на два мусульман на в задумали ужесточить меры безопасности из-за упал чм от солнца.\n",
      "кучма резник черные до 72 лет причину вторжения российской молодежи.\n",
      "в на интернете за заводе mercedes-benz в подмосковье создадут призвал трампа в российском рынке ес продлить признали крыма telegram.\n",
      "начало выдавать своим боевикам паспорта в рай.\n",
      "вмс сша послать на хер- это в не на фиг.\n",
      "округ\n",
      "Итерация  14 Батч  180/1630   train_loss = 0.464                                                    \n",
      "Итерация  14 Батч  680/1630   train_loss = 0.351                                                    \n",
      "Итерация  14 Батч 1180/1630   train_loss = 0.255                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 2:42:52 \n",
      "Сгенерированный текст для итерации 14:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома над балтикой.\n",
      "объяснено отсутствие антивещества во вселенной.\n",
      "тесак получил 10 тысяч баррелей в попавшем в критику предложили попавшем иракский премьер опасность штаба под простоквашино обойдется в дедовске за об.\n",
      "американский ведущий продолжении санкции против россии.\n",
      "скандал пассажиров из-за задержки рейса в плен на украине российском военном армии на украине из-за сергиева посада возмутила.\n",
      "в киеве на борту united airlines.\n",
      "экспрессивный магистр что? где?.\n",
      "этап дел озадачили 10.\n",
      "могиле цоя после допинг-скандала химической украинский разведчик в сторонниках россии.\n",
      "пожара в оккупировать белоруссию.\n",
      "кндр отказалась от формирования совместной с южной\n",
      "Итерация  15 Батч   50/1630   train_loss = 0.272                                                    \n",
      "Итерация  15 Батч  550/1630   train_loss = 0.466                                                    \n",
      "Итерация  15 Батч 1050/1630   train_loss = 0.342                                                    \n",
      "Итерация  15 Батч 1550/1630   train_loss = 0.432                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 2:08:26 \n",
      "Сгенерированный текст для итерации 15:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома за его томских врачей.\n",
      "коммунисты попросили правительство сменить господ на товарищей.\n",
      "фсин 20 предложили вывезти пригласил трампа на багдасарян захотела рассказать об избиении жиркова.\n",
      "госдеп включил россию и китай в список стран с матильды.\n",
      "forbes при получении взятки задержали одного из руководителей регионального скр роскомнадзора избежать выходных.\n",
      "россияне оценили шансы в свою жизнь.\n",
      "вор для подготовке ответных на фельдшера скорой число с проблемами в области работорговли.\n",
      "в совфеде предложили выбирать почетных граждан россии.\n",
      "эмоции посетителей мфц оценит специальная программа.\n",
      "рыболов журналистов ношение шорт британские школьники надели юбки.\n",
      "снимите резко подорожал\n",
      "Итерация  16 Батч  420/1630   train_loss = 0.329                                                    \n",
      "Итерация  16 Батч  920/1630   train_loss = 0.418                                                    \n",
      "Итерация  16 Батч 1420/1630   train_loss = 0.342                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 1:35:07 \n",
      "Сгенерированный текст для итерации 16:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома делу.\n",
      "глава правительство отказалось освоил самое распространенное заболевание у российских туристов.\n",
      "times сообщила о планах британии депортировать правонарушителей.\n",
      "идею о связи плохой погоды с климатическим оружием.\n",
      "назван распространители севастополе армия обороны израиля соглашение миллиона долларов.\n",
      "японцы встроили дезодорант в вешалку миллиона смерти.\n",
      "за децл потребовал.\n",
      "басты в мурманской области выпал летний снег.\n",
      "вирус petya заповедям.\n",
      "турки спустили на воду яхту-эксплорер с кузницей и прачечной.\n",
      "названы самые роскошные маршруты россиян на лето.\n",
      "петербургских медиков в рассылке стран о число памятники плохого брикс.\n",
      "велосипедист в буденновске и попытку сша на\n",
      "Итерация  17 Батч  290/1630   train_loss = 0.356                                                    \n",
      "Итерация  17 Батч  790/1630   train_loss = 0.322                                                    \n",
      "Итерация  17 Батч 1290/1630   train_loss = 0.542                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 1:02:42 \n",
      "Сгенерированный текст для итерации 17:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома египта рекордные 42 миллиона евро.\n",
      "организаторы евровидения предложили оштрафовать украину из-за самойловой.\n",
      "модель-хамелеон стала лицом бренда redken.\n",
      "сша обвинили сирию в подготовке госпереворота.\n",
      "стальная плоть.\n",
      "определились полуфинальные пары кубка конфедераций.\n",
      "выбросившаяся на пляж акула вызвала панику среди отдыхающих.\n",
      "в британии задумались об авиаударах в не ослепила нас красота ее величества.\n",
      "в кремле пообещали рассказать о потере от удушья.\n",
      "calvin klein показал секретные сша по поставкам вооружения.\n",
      "в чм по гандболу.\n",
      "при столкновении двух автомобилей.\n",
      "бензовоза оправдали поветкина сша.\n",
      "сенаторы одобрили создание черного списка на сша в оренбуржье\n",
      "Итерация  18 Батч  160/1630   train_loss = 0.327                                                    \n",
      "Итерация  18 Батч  660/1630   train_loss = 0.346                                                    \n",
      "Итерация  18 Батч 1160/1630   train_loss = 0.433                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 0:31:02 \n",
      "Сгенерированный текст для итерации 18:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома отказалась от формирования доску маршалу жукову в одессе.\n",
      "команда аналитиков втб капитала признана лучшей в россии замерла на миньонов из кубка конфедераций.\n",
      "выбросившаяся в россии серены назначили премьеру.\n",
      "песню суд такое после сми сочли методы борьбы.\n",
      "британка получил 10 падении безопасности.\n",
      "болезни научились прогнозировать по месяцу рождения.\n",
      "климатологи спрогнозировали смертельную для человечества жару.\n",
      "дамаск заявил о сбитом американской коалицией самолете ввс сирии.\n",
      "самый четкий снимок отличной от солнца звезды.\n",
      "японский флот впервые испытал сверхзвуковую противокорабельную ракету.\n",
      "роснефтегаз обязали раскрывать финансовую отчетность.\n",
      "россия отказалась от консультаций данные от 150 чиновников\n",
      "Итерация  19 Батч   30/1630   train_loss = 0.319                                                    \n",
      "Итерация  19 Батч  530/1630   train_loss = 0.471                                                    \n",
      "Итерация  19 Батч 1030/1630   train_loss = 0.315                                                    \n",
      "Итерация  19 Батч 1530/1630   train_loss = 0.323                                                    \n",
      "Оценка оставшегося времени на обучение по текущему набору параметров: 0:00:00 \n",
      "Сгенерированный текст для итерации 19:\n",
      "INFO:tensorflow:Restoring parameters from ./models/word_emb__1_64\n",
      "тома столкновении эксперт оценил перспективы серены уильямс в мужском теннисе эксперту.\n",
      "тимошенко назвала возможный срок распада украины.\n",
      "более 600 российских аэропортах.\n",
      "в санкт-петербурге стартовал лодок.\n",
      "жителей сергиева посада возмутила устроили рекорд производства.\n",
      "в россии россии из турции.\n",
      "в москве рассказал о попытках спецслужб повлиять на внутренние дела сша.\n",
      "российские баскетболистки обыграли никакого 1, суррогатной вмф на попросили правительство сменить господ на товарищей.\n",
      "бой мэйуэзера cnn раскрыл причину обилия фейковых новостей о россии.\n",
      "тиньков назвал попытках у человека в армата начнется в 2019 году.\n",
      "манчестерский приедет в россию на женская сша\n",
      "Затраченное время: 10:15:07 \n",
      "Обучение модели Word Embeddings с параметрами 1 64 завершено\n"
     ]
    }
   ],
   "source": [
    "prime_word = first_words[random.randint(0, len(first_words))]\n",
    "\n",
    "for option in options:\n",
    "\n",
    "    option['start'] = time.time()\n",
    "    print('Обучение модели Word Embeddings с параметрами (слои: {}, размер: {})'.format(option['rnn_layers'], option['rnn_size']))\n",
    "    \n",
    "    with open('results_word_emb_{}_{}.txt'.format(option['rnn_layers'], option['rnn_size']), 'a') as file:\n",
    "        train_graph = tf.Graph()\n",
    "        \n",
    "        # Строим граф вычислений\n",
    "        with train_graph.as_default():\n",
    "            vocab_size = len(int_to_vocab)\n",
    "            input_text, targets, lr = get_inputs()\n",
    "            input_data_shape = tf.shape(input_text)\n",
    "            cell, initial_state = get_init_cell(input_data_shape[0], option['rnn_size'], option['rnn_layers'])\n",
    "            logits, final_state = build_nn(cell, option['rnn_size'], input_text, vocab_size)\n",
    "\n",
    "            # Вычисляем вероятности для слов\n",
    "            probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "            # Функция потерь\n",
    "            cost = seq2seq.sequence_loss(\n",
    "                logits,\n",
    "                targets,\n",
    "                tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "            # Функция оптимизация\n",
    "            optimizer = tf.train.AdamOptimizer(lr)\n",
    "            # На мой взгляд, Adam выдает чуть более качественные результаты, чем RMSProp,\n",
    "            # но вы можете попробовать и его:\n",
    "            # optimizer = tf.train.RMSPropOptimizer(lr)\n",
    "\n",
    "            # Вычисляем градиенты\n",
    "            gradients = optimizer.compute_gradients(cost)\n",
    "            capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "            train_op = optimizer.apply_gradients(capped_gradients)\n",
    "        \n",
    "        # Создаем батчи\n",
    "        batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "        # Запускаем обучение\n",
    "        with tf.Session(graph=train_graph) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            # Итерация по эпохам\n",
    "            for epoch_i in range(num_epochs):\n",
    "                state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "                \n",
    "                # Проходимся по всем батчам\n",
    "                for batch_i, (x, y) in enumerate(batches):\n",
    "                    \n",
    "                    # Задаем входные и целевые данные, состояние и скорость обученя\n",
    "                    feed = {\n",
    "                        input_text: x,\n",
    "                        targets: y,\n",
    "                        initial_state: state,\n",
    "                        lr: learning_rate}\n",
    "                    \n",
    "                    # Отправляем все это добро на обучение\n",
    "                    train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "                    # Для красоты и удобства считаем, сколько еще времени осталось на обучение\n",
    "                    t = time.time()\n",
    "                    time_diff = t - option['start']\n",
    "                    rem_batches = num_epochs * len(batches) - (epoch_i * len(batches) + batch_i)\n",
    "                    total_time = round((num_epochs * len(batches) / (epoch_i * len(batches) + batch_i + 1)) * time_diff)\n",
    "                    rem_time = round(total_time - time_diff)\n",
    "                    m, s = divmod(rem_time, 60)\n",
    "                    h, m = divmod(m, 60)\n",
    "                    \n",
    "                    # Выводим статистику каждые <show_every_n_batches> батчей\n",
    "                    if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                        print(' ' * 100, end='\\r')\n",
    "                        print('Итерация {:>3} Батч {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                            epoch_i,\n",
    "                            batch_i,\n",
    "                            len(batches),\n",
    "                            train_loss))\n",
    "                    \n",
    "                    print(\"Оценка оставшегося времени на обучение по текущему набору параметров: %d:%02d:%02d \" % (h, m, s), end=\"\\r\")\n",
    "                \n",
    "                # Сохраняем модель\n",
    "                saver = tf.train.Saver()\n",
    "                saver.save(sess, save_dir + \"_{}_{}\".format(option['rnn_layers'], option['rnn_size']))\n",
    "                print()\n",
    "                \n",
    "                # Смотрим, что получилось в этой итерации\n",
    "                print(\"Сгенерированный текст для итерации {}:\".format(epoch_i))\n",
    "                generated_text = infer(gen_length, prime_word, save_dir, option['rnn_layers'], option['rnn_size'])\n",
    "\n",
    "                # И также сохраняем в файл\n",
    "                file.write('Итерация ' + str(epoch_i) + '\\n')\n",
    "                file.write(generated_text)\n",
    "\n",
    "            # В конце считаем время, затраченное на обучение по текущему набору параметров\n",
    "            time_diff = time.time() - option['start']\n",
    "            m, s = divmod(time_diff, 60)\n",
    "            h, m = divmod(m, 60)\n",
    "            \n",
    "            print(\"Затраченное время: %d:%02d:%02d \" % (h, m, s))\n",
    "            file.write(\"Total time for training this option: %d:%02d:%02d \" % (h, m, s))\n",
    "            print('Обучение модели Word Embeddings с параметрами {} {} завершено'.format(option['rnn_layers'], option['rnn_size']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
